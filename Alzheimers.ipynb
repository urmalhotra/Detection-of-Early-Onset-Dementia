{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "pd.options.display.max_rows = 100\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in the data\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "df = pd.read_csv(\"oasis_longitudinal.csv\")\n",
    "print(df)\n",
    "\n",
    "#extracting pateints only from first and second visits\n",
    "df = df.loc[df['Visit'].isin([1,2])]\n",
    "print(df)\n",
    "print(\"Dataset has \" + str(df.shape[0]) +\" values, along \" + str(df.shape[1]) +\" dimensions.\")\n",
    "print(\"Participents Sex: \" + str(len(df.loc[df['M/F'].isin(['M'])])) +\" Males and \" + str(len(df.loc[df['M/F'].isin(['F'])])) +\" Females.\")\n",
    "print(\"Class distribution for demented and non-demented patients in reduced dataset is as follows:\" )\n",
    "print(\"Demented: \" + str(len(df.loc[df['Group']== 'Demented'])))\n",
    "print(\"Non-Demented: \" + str(len(df.loc[df['Group']== 'Nondemented'])))\n",
    "print(\"Converted from Non-Demented to Demented: \" + str(len(df.loc[df['Group']== 'Converted'])))\n",
    "# Remove all converted patients\n",
    "df.drop(df[df['Group'] == 'Converted'].index, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing categorical variables group and gender to numeric\n",
    "df['M/F'].replace(['M', 'F'],\n",
    "                        [0, 1], inplace=True)\n",
    "df['Group'].replace(['Demented', 'Nondemented'],\n",
    "                        [0, 1], inplace=True)\n",
    "del df['CDR']\n",
    "del df['Subject ID']\n",
    "del df['MRI ID']\n",
    "del df['Hand']\n",
    "del df['Visit']\n",
    "#printing correlation matrix\n",
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFpr\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "feature_list = list(df.columns)\n",
    "# target stays stable\n",
    "y = df[['Group']]\n",
    "\n",
    "y = y.iloc[0:,:].values\n",
    "feature_list.remove('Group')\n",
    "X = df[feature_list]\n",
    "X = X.iloc[0:,:].values\n",
    "acc_list = []\n",
    "\n",
    "if np.sum(np.isnan(X)):\n",
    "  #print('Total of NaN before imputation:', np.sum(np.isnan(X)))\n",
    "  imputer = KNNImputer(n_neighbors=4, weights=\"uniform\")\n",
    "  X1 = imputer.fit_transform(X)\n",
    "\n",
    "for j in range(20):\n",
    "  acc_temp= []\n",
    "  for i in range(1,10):\n",
    "    select = SelectKBest(chi2, k=i)\n",
    "    X_new = select.fit_transform(X1, y)\n",
    "    # train/test/val = 60/20/20\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y,\n",
    "    test_size=0.2, random_state= 19)\n",
    "    # Use the same function above for the validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "    test_size=0.25, random_state = 7) # 0.25 x 0.8 = 0.2\n",
    "    \n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto', kernel = 'poly', probability=True))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    probs = clf.predict_proba(X_val)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_val, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    acc = np.round(accuracy_score(y_val, y_pred), 3)\n",
    "    acc_temp.append(roc_auc)\n",
    "  acc_list.append(acc_temp)\n",
    "print(np.mean(acc_list, axis = 0))\n",
    "to_plot = np.average(acc_list, axis=0)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(ncols = 1, figsize= (12,8))\n",
    "\n",
    "# MMSE\n",
    "ax.plot(list(range(1,10)), to_plot)\n",
    "ax.set_title(\"Performance with k features (SVM)\")\n",
    "ax.set_xlabel(\"k (Features Used)\")\n",
    "ax.set_ylabel(\"AUC\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFpr\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "feature_list = list(df.columns)\n",
    "# target stays stable\n",
    "y = df[['Group']]\n",
    "y = y.iloc[1:,:].values\n",
    "feature_list.remove('Group')\n",
    "X = df[feature_list]\n",
    "X = X.iloc[1:,:].values\n",
    "acc_list = []\n",
    "\n",
    "if np.sum(np.isnan(X)):\n",
    "  #print('Total of NaN before imputation:', np.sum(np.isnan(X)))\n",
    "  imputer = KNNImputer(n_neighbors=4, weights=\"uniform\")\n",
    "  X1 = imputer.fit_transform(X)\n",
    "\n",
    "for j in range(20):\n",
    "  acc_temp= []\n",
    "  for i in range(1,10):\n",
    "    select = SelectKBest(chi2, k=i)\n",
    "    X_new = select.fit_transform(X1, y)\n",
    "    # train/test/val = 60/20/20\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y,\n",
    "    test_size=0.2, random_state= 19)\n",
    "    # Use the same function above for the validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "    test_size=0.25, random_state = 7) # 0.25 x 0.8 = 0.2\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    probs = clf.predict_proba(X_val)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_val, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    acc = np.round(accuracy_score(y_val, y_pred), 3)\n",
    "    acc_temp.append(roc_auc)\n",
    "  acc_list.append(acc_temp)\n",
    "print(np.mean(acc_list, axis = 0))\n",
    "to_plot = np.average(acc_list, axis=0)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(ncols = 1, figsize= (12,8))\n",
    "\n",
    "# MMSE\n",
    "ax.plot(list(range(1,10)), to_plot)\n",
    "ax.set_title(\"Performance with k features (Decision Tree)\")\n",
    "ax.set_xlabel(\"k (Features Used)\")\n",
    "ax.set_ylabel(\"AUC\")\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFpr\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "feature_list = list(df.columns)\n",
    "# target stays stable\n",
    "y = df[['Group']]\n",
    "y = y.iloc[1:,:].values\n",
    "feature_list.remove('Group')\n",
    "X = df[feature_list]\n",
    "X = X.iloc[1:,:].values\n",
    "acc_list = []\n",
    "\n",
    "if np.sum(np.isnan(X)):\n",
    "  #print('Total of NaN before imputation:', np.sum(np.isnan(X)))\n",
    "  imputer = KNNImputer(n_neighbors=4, weights=\"uniform\")\n",
    "  X1 = imputer.fit_transform(X)\n",
    "\n",
    "for j in range(20):\n",
    "  acc_temp= []\n",
    "  for i in range(1,10):\n",
    "    select = SelectKBest(chi2, k=i)\n",
    "    X_new = select.fit_transform(X1, y)\n",
    "    #print columns if i = 5\n",
    "    if (i == 5):\n",
    "      print(select.get_support(indices=False))\n",
    "    # train/test/val = 60/20/20\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y,\n",
    "    test_size=0.2, random_state= 19)\n",
    "    # Use the same function above for the validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "    test_size=0.25, random_state = 7) # 0.25 x 0.8 = 0.2\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    probs = clf.predict_proba(X_val)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_val, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    acc = np.round(accuracy_score(y_val, y_pred), 3)\n",
    "    acc_temp.append(roc_auc)\n",
    "  acc_list.append(acc_temp)\n",
    "print(np.mean(acc_list, axis = 0))\n",
    "to_plot = np.average(acc_list, axis=0)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(ncols = 1, figsize= (12,8))\n",
    "\n",
    "# MMSE\n",
    "ax.plot(list(range(1,10)), to_plot)\n",
    "ax.set_title(\"Performance with k features (Logistic Regression)\")\n",
    "ax.set_xlabel(\"k (Features Used)\")\n",
    "ax.set_ylabel(\"AUC\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "#use ideal value of k\n",
    "select = SelectKBest(chi2, k=5)\n",
    "X_new = select.fit_transform(X1, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y,\n",
    "test_size=0.2, random_state= 19)\n",
    "\n",
    "# Use the same function above for the validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "test_size=0.25, random_state = 7) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "print(\"X_train size:\",len(X_train), 'Shape:',X_train.shape)\n",
    "print(\"X_test size:\",len(X_test),'Shape:',X_test.shape)\n",
    "print(\"X_val size:\",len(X_val),'Shape:',X_val.shape)\n",
    "print(\"y_train size:\",len(y_train),'Shape:',y_train.shape)\n",
    "print(\"y_test size:\",len(y_test),'Shape:',y_test.shape)\n",
    "print(\"y_val size:\",len(y_val),'Shape:',y_val.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying different models to see difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "probs = clf.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "acc = np.round(accuracy_score(y_val, y_pred), 3)\n",
    "print(\"Accuracy is: \" + str(acc))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in range(len(kernels)):\n",
    "  clf = make_pipeline(StandardScaler(), SVC(gamma='auto', kernel = kernels[i], probability=True))\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.predict(X_val)\n",
    "  probs = clf.predict_proba(X_val)\n",
    "  preds = probs[:,1]\n",
    "  fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "  roc_auc = metrics.auc(fpr, tpr)\n",
    "  acc = np.round(accuracy_score(y_val, y_pred), 3)\n",
    "  print(\"Accuracy is: \" + str(acc))\n",
    "  plt.title('Receiver Operating Characteristic: Kernel = ' + kernels[i])\n",
    "  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "  plt.legend(loc = 'lower right')\n",
    "  plt.plot([0, 1], [0, 1],'r--')\n",
    "  plt.xlim([0, 1])\n",
    "  plt.ylim([0, 1])\n",
    "  plt.ylabel('True Positive Rate')\n",
    "  plt.xlabel('False Positive Rate')\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression (Model Decided to Use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#tune solver\n",
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'sag']\n",
    "for  i in range(len(solvers)):\n",
    "  clf = LogisticRegression(solver = solvers[i])\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.predict(X_val)\n",
    "  probs = clf.predict_proba(X_val)\n",
    "  preds = probs[:,1]\n",
    "  fpr, tpr, threshold = metrics.roc_curve(y_val, preds)\n",
    "  roc_auc = metrics.auc(fpr, tpr)\n",
    "  fig, ax = plt.subplots(ncols = 1, figsize= (12,8))\n",
    "  print(\"Accuracy is: \" + str(acc))\n",
    "  plt.title('Receiver Operating Characteristic using solver = '+solvers[i])\n",
    "  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "  plt.legend(loc = 'lower right')\n",
    "  plt.plot([0, 1], [0, 1],'r--')\n",
    "  plt.xlim([0, 1])\n",
    "  plt.ylim([0, 1])\n",
    "  plt.ylabel('True Positive Rate')\n",
    "  plt.xlabel('False Positive Rate')\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'sag']\n",
    "#after tuning decided to use lbfgs\n",
    "clf = LogisticRegression(solver = solvers[0])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "probs = clf.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "#plotting confusion matrix\n",
    "color = 'white'\n",
    "matrix = plot_confusion_matrix(clf, X_test, y_test, cmap=plt.cm.Blues)\n",
    "matrix.ax_.set_title('Confusion Matrix', color=color)\n",
    "plt.xlabel('Predicted Label', color=color)\n",
    "plt.ylabel('True Label', color=color)\n",
    "plt.gcf().axes[0].tick_params(colors=color)\n",
    "plt.gcf().axes[1].tick_params(colors=color)\n",
    "plt.show()\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "fig, ax = plt.subplots(ncols = 1, figsize= (12,8))\n",
    "print(\"Accuracy is: \" + str(acc))\n",
    "plt.title('Receiver Operating Characteristic using all 9 features')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a48a3bf61ba1ad3797316967cef61833253dbd783bf3d01a40ad59f8de2bb650"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
